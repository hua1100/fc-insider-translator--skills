#!/usr/bin/env python3
"""
æ–¹æ¡ˆ 2: æ™ºèƒ½è¿‡æ»¤ - è¯»å–æ‰€æœ‰å†…å®¹åæ™ºèƒ½å¤„ç†

å‡è®¾ï¼š
- è¯»å–å•å…ƒæ ¼çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹
- ä½¿ç”¨æ™ºèƒ½è¿‡æ»¤ç®—æ³•ç§»é™¤å ä½ç¬¦
- æ”¯æŒå¤šç§å ä½ç¬¦æ¨¡å¼
- æ”¯æŒå¤šè¡Œæ–‡æœ¬å¤„ç†

ä½¿ç”¨æ–¹æ³•ï¼š
python3 update_fc_insider_smart.py \
  --input "input.docx" \
  --translations "translations.json" \
  --output "output.docx" \
  --author "Translator Name" \
  --verbose
"""

import argparse
import json
import sys
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import re

try:
    from docx import Document
    from docx.oxml import parse_xml
    from docx.oxml.ns import qn
    from docx.shared import RGBColor
except ImportError:
    print("é”™è¯¯ï¼šéœ€è¦å®‰è£… python-docx")
    print("è¿è¡Œ: pip install python-docx")
    sys.exit(1)


def smart_filter_placeholders(text: str, verbose: bool = False) -> str:
    """
    æ™ºèƒ½è¿‡æ»¤å ä½ç¬¦

    å¤„ç†å¤šç§å ä½ç¬¦æ¨¡å¼ï¼š
    - "<0/>"åœ¨ç¬¬ <1/> é 
    - "<2/>"
    - å¸¦å¼•å·çš„å ä½ç¬¦ï¼š"<0/>"
    - ç‹¬ç«‹çš„å ä½ç¬¦ï¼š<1/>

    ä¿ç•™çœŸå®å†…å®¹
    """
    original = text

    # 1. ç§»é™¤å¼•å·åŒ…è£¹çš„å ä½ç¬¦ï¼š  "<0/>"
    text = re.sub(r'"<\d+/>"', '', text)

    # 2. ç§»é™¤ç‹¬ç«‹çš„å ä½ç¬¦ï¼š <1/>
    text = re.sub(r'<\d+/>', '', text)

    # 3. æ¸…ç†å¤šä½™çš„ç©ºç™½
    # ç§»é™¤è¡Œé¦–å°¾ç©ºç™½
    lines = [line.strip() for line in text.split('\n')]
    # ç§»é™¤ç©ºè¡Œ
    lines = [line for line in lines if line]
    # é‡æ–°ç»„åˆ
    text = '\n'.join(lines)

    # 4. æ¸…ç†å¤šä½™çš„ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text).strip()

    if verbose and original != text:
        print(f"    è¿‡æ»¤å‰: '{original[:80]}...'")
        print(f"    è¿‡æ»¤å: '{text[:80]}...'")

    return text


def get_cell_text_smart(cell, verbose: bool = False) -> str:
    """
    æ™ºèƒ½è¯»å–å•å…ƒæ ¼æ–‡æœ¬

    æ–¹æ³•ï¼š
    1. è¯»å–æ‰€æœ‰æ®µè½çš„æ‰€æœ‰æ–‡æœ¬
    2. åº”ç”¨æ™ºèƒ½è¿‡æ»¤
    3. è¿”å›æ¸…ç†åçš„æ–‡æœ¬
    """
    # æ”¶é›†æ‰€æœ‰æ–‡æœ¬
    all_text_parts = []

    for paragraph in cell.paragraphs:
        para_text = paragraph.text.strip()
        if para_text:
            all_text_parts.append(para_text)

    # ç»„åˆæ‰€æœ‰æ®µè½
    full_text = '\n'.join(all_text_parts)

    # åº”ç”¨æ™ºèƒ½è¿‡æ»¤
    filtered_text = smart_filter_placeholders(full_text, verbose)

    return filtered_text


def get_cell_text_by_style_smart(cell, target_style: Optional[str] = None, verbose: bool = False) -> str:
    """
    æŒ‰æ ·å¼æ™ºèƒ½è¯»å–å•å…ƒæ ¼æ–‡æœ¬

    Args:
        target_style: None = è¯»å–æ‰€æœ‰æ ·å¼
                     "Tag" = åªè¯»å– Tag æ ·å¼
                     "NotTag" = åªè¯»å–é Tag æ ·å¼
    """
    all_text_parts = []

    for paragraph in cell.paragraphs:
        for run in paragraph.runs:
            run_element = run._element
            rpr = run_element.find(qn('w:rPr'))

            has_tag_style = False
            if rpr is not None:
                r_style = rpr.find(qn('w:rStyle'))
                if r_style is not None:
                    style_val = r_style.get(qn('w:val'))
                    if style_val == 'Tag':
                        has_tag_style = True

            # æ ¹æ® target_style å†³å®šæ˜¯å¦åŒ…å«
            include = False
            if target_style is None:
                include = True
            elif target_style == "Tag" and has_tag_style:
                include = True
            elif target_style == "NotTag" and not has_tag_style:
                include = True

            if include and run.text:
                all_text_parts.append(run.text)

    # ç»„åˆæ–‡æœ¬
    full_text = ''.join(all_text_parts)

    # åº”ç”¨æ™ºèƒ½è¿‡æ»¤
    filtered_text = smart_filter_placeholders(full_text, verbose)

    return filtered_text


def analyze_cell_structure(cell) -> Dict:
    """
    åˆ†æå•å…ƒæ ¼ç»“æ„

    è¿”å›è¯¦ç»†çš„ç»“æ„ä¿¡æ¯ï¼Œå¸®åŠ©è°ƒè¯•
    """
    structure = {
        'paragraphs': [],
        'has_tag_style': False,
        'has_non_tag_style': False,
        'total_runs': 0
    }

    for para_idx, paragraph in enumerate(cell.paragraphs):
        para_info = {
            'index': para_idx,
            'text': paragraph.text,
            'runs': []
        }

        for run_idx, run in enumerate(paragraph.runs):
            run_element = run._element
            rpr = run_element.find(qn('w:rPr'))

            style_val = None
            if rpr is not None:
                r_style = rpr.find(qn('w:rStyle'))
                if r_style is not None:
                    style_val = r_style.get(qn('w:val'))

            run_info = {
                'index': run_idx,
                'text': run.text,
                'style': style_val,
                'is_tag_style': style_val == 'Tag'
            }

            para_info['runs'].append(run_info)
            structure['total_runs'] += 1

            if style_val == 'Tag':
                structure['has_tag_style'] = True
            else:
                structure['has_non_tag_style'] = True

        structure['paragraphs'].append(para_info)

    return structure


def has_track_changes_enabled(doc) -> bool:
    """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²å¯ç”¨è¿½è¸ªä¿®è®¢"""
    try:
        settings = doc.settings.element
        track_revisions = settings.find(qn('w:trackRevisions'))
        return track_revisions is not None
    except:
        return False


def enable_track_changes(doc):
    """å¯ç”¨æ–‡æ¡£å±‚çº§çš„è¿½è¸ªä¿®è®¢"""
    try:
        settings = doc.settings.element
        track_revisions = settings.find(qn('w:trackRevisions'))
        if track_revisions is None:
            track_revisions = parse_xml('<w:trackRevisions {} />'.format(
                'xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main"'
            ))
            settings.append(track_revisions)
    except Exception as e:
        print(f"âš  è­¦å‘Šï¼šæ— æ³•å¯ç”¨æ–‡æ¡£å±‚çº§è¿½è¸ªä¿®è®¢: {e}")


def replace_cell_with_track_changes_smart(
    cell,
    old_text: str,
    new_text: str,
    author: str,
    date_str: str,
    revision_id: int,
    reading_strategy: str = 'all',
    verbose: bool = False
) -> bool:
    """
    ä½¿ç”¨è¿½è¸ªä¿®è®¢æ›¿æ¢å•å…ƒæ ¼å†…å®¹

    Args:
        reading_strategy:
            'all' - è¯»å–æ‰€æœ‰æ–‡æœ¬åè¿‡æ»¤
            'tag_only' - åªè¯»å– Tag æ ·å¼åè¿‡æ»¤
            'non_tag_only' - åªè¯»å–é Tag æ ·å¼åè¿‡æ»¤
    """
    # æ ¹æ®ç­–ç•¥é€‰æ‹©è¯»å–æ–¹æ³•
    if reading_strategy == 'all':
        current_text = get_cell_text_smart(cell, verbose)
    elif reading_strategy == 'tag_only':
        current_text = get_cell_text_by_style_smart(cell, "Tag", verbose)
    elif reading_strategy == 'non_tag_only':
        current_text = get_cell_text_by_style_smart(cell, "NotTag", verbose)
    else:
        current_text = get_cell_text_smart(cell, verbose)

    # éªŒè¯
    if current_text != old_text:
        print(f"  âœ— æ–‡æœ¬ä¸åŒ¹é…")
        print(f"    é¢„æœŸ: '{old_text[:100]}...'")
        print(f"    å®é™…: '{current_text[:100]}...'")

        if verbose:
            print(f"\n  === å•å…ƒæ ¼ç»“æ„åˆ†æ ===")
            structure = analyze_cell_structure(cell)
            print(f"  æ€» runs: {structure['total_runs']}")
            print(f"  æœ‰ Tag æ ·å¼: {structure['has_tag_style']}")
            print(f"  æœ‰é Tag æ ·å¼: {structure['has_non_tag_style']}")
            for para in structure['paragraphs']:
                print(f"\n  æ®µè½ {para['index']}: {para['text'][:50]}")
                for run in para['runs']:
                    print(f"    Run {run['index']}: æ ·å¼={run['style']}, æ–‡æœ¬='{run['text'][:30]}'")

        return False

    # æ¸…ç©ºå•å…ƒæ ¼
    for paragraph in cell.paragraphs:
        for run in paragraph.runs:
            run._element.getparent().remove(run._element)

    # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ®µè½
    if not cell.paragraphs:
        cell.add_paragraph()

    paragraph = cell.paragraphs[0]

    # æ·»åŠ åˆ é™¤æ ‡è®°ï¼ˆæ—§æ–‡æœ¬ï¼‰
    del_run = paragraph.add_run(old_text)
    del_run_element = del_run._element

    # åŒ…è£…ä¸ºåˆ é™¤
    del_element = parse_xml(f'''
        <w:del w:id="{revision_id}" w:author="{author}" w:date="{date_str}"
               xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">
        </w:del>
    ''')

    parent = del_run_element.getparent()
    parent.remove(del_run_element)
    del_element.append(del_run_element)
    paragraph._element.append(del_element)

    # æ·»åŠ æ’å…¥æ ‡è®°ï¼ˆæ–°æ–‡æœ¬ï¼‰
    ins_element = parse_xml(f'''
        <w:ins w:id="{revision_id + 1}" w:author="{author}" w:date="{date_str}"
               xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">
        </w:ins>
    ''')

    ins_run_xml = f'''
        <w:r xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">
            <w:t xml:space="preserve">{new_text}</w:t>
        </w:r>
    '''

    ins_run_element = parse_xml(ins_run_xml)
    ins_element.append(ins_run_element)
    paragraph._element.append(ins_element)

    return True


def find_table(doc) -> Optional:
    """æŸ¥æ‰¾æ–‡æ¡£ä¸­çš„ç¬¬ä¸€ä¸ªè¡¨æ ¼"""
    if not doc.tables:
        return None
    return doc.tables[0]


def update_translations(
    input_path: str,
    translations_path: str,
    output_path: str,
    author: str = "Translator",
    verbose: bool = False,
    reading_strategy: str = 'all'
) -> Tuple[int, int]:
    """
    æ›´æ–°ç¿»è¯‘

    Args:
        reading_strategy: 'all', 'tag_only', 'non_tag_only'
    """
    # åŠ è½½æ–‡æ¡£
    print(f"\nğŸ“– åŠ è½½æ–‡æ¡£: {input_path}")
    doc = Document(input_path)

    # å¯ç”¨è¿½è¸ªä¿®è®¢
    if has_track_changes_enabled(doc):
        print("âœ“ æ–‡æ¡£å±‚çº§è¿½è¸ªä¿®è®¢å·²å­˜åœ¨")
    else:
        enable_track_changes(doc)
        print("âœ“ å·²å¯ç”¨æ–‡æ¡£å±‚çº§è¿½è¸ªä¿®è®¢")

    # åŠ è½½ç¿»è¯‘
    with open(translations_path, 'r', encoding='utf-8') as f:
        translations = json.load(f)

    # æŸ¥æ‰¾è¡¨æ ¼
    table = find_table(doc)
    if not table:
        raise ValueError("æ–‡æ¡£ä¸­æœªæ‰¾åˆ°è¡¨æ ¼")

    # æ„å»º segment_id -> row æ˜ å°„
    row_map = {}
    for i, row in enumerate(table.rows[1:], start=1):  # è·³è¿‡è¡¨å¤´
        if len(row.cells) >= 4:
            segment_id = row.cells[0].text.strip()
            if segment_id:
                row_map[segment_id] = i

    print(f"\n{'='*80}")
    print(f"FC Insider ç¿»è¯‘æ›´æ–° - æ–¹æ¡ˆ 2 (æ™ºèƒ½è¿‡æ»¤)")
    print(f"è¯»å–ç­–ç•¥: {reading_strategy}")
    print(f"ä½œè€…: {author}")
    print(f"ç¿»è¯‘æ•°é‡: {len(translations)}")
    print(f"{'='*80}")

    success_count = 0
    fail_count = 0
    date_str = datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ")
    revision_id = 1000

    print(f"\nå¼€å§‹å¤„ç† {len(translations)} ä¸ªç¿»è¯‘...")
    print("="*80)

    for idx, translation in enumerate(translations, 1):
        segment_id = translation.get('segment_id')
        old_text = translation.get('old_translation', '').strip()
        new_text = translation.get('new_translation', '').strip()

        print(f"[{idx}/{len(translations)}] å¤„ç† {segment_id}...", end=" ")

        if not segment_id or segment_id not in row_map:
            print(f"âœ— Segment ID æœªæ‰¾åˆ°")
            fail_count += 1
            continue

        row_idx = row_map[segment_id]
        target_cell = table.rows[row_idx].cells[3]

        if verbose:
            print()

        success = replace_cell_with_track_changes_smart(
            target_cell,
            old_text,
            new_text,
            author,
            date_str,
            revision_id,
            reading_strategy,
            verbose
        )

        if success:
            print("âœ“" if not verbose else "  âœ“ æˆåŠŸ")
            success_count += 1
            revision_id += 2
        else:
            fail_count += 1

    print("="*80)
    print(f"\n{'âœ“ æ›´æ–°å®Œæˆ' if fail_count == 0 else 'âš  æ›´æ–°å®Œæˆï¼ˆæœ‰å¤±è´¥é¡¹ï¼‰'}: {success_count}/{len(translations)}")
    if fail_count > 0:
        print(f"âœ— å¤±è´¥: {fail_count}")
    print("="*80)

    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜æ–‡æ¡£: {output_path}")
    doc.save(output_path)
    print("âœ“ å®Œæˆ")

    return success_count, fail_count


def main():
    parser = argparse.ArgumentParser(
        description='æ–¹æ¡ˆ 2: æ™ºèƒ½è¿‡æ»¤ - è¯»å–æ‰€æœ‰å†…å®¹åæ™ºèƒ½å¤„ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # ç­–ç•¥ 1ï¼šè¯»å–æ‰€æœ‰æ–‡æœ¬ï¼ˆé»˜è®¤ï¼‰
  python3 update_fc_insider_smart.py \\
    --input "input.docx" \\
    --translations "translations.json" \\
    --output "output.docx" \\
    --author "Gemini" \\
    --strategy all \\
    --verbose

  # ç­–ç•¥ 2ï¼šåªè¯»å– Tag æ ·å¼æ–‡æœ¬
  python3 update_fc_insider_smart.py \\
    --input "input.docx" \\
    --translations "translations.json" \\
    --output "output.docx" \\
    --author "Gemini" \\
    --strategy tag_only \\
    --verbose

  # ç­–ç•¥ 3ï¼šåªè¯»å–é Tag æ ·å¼æ–‡æœ¬
  python3 update_fc_insider_smart.py \\
    --input "input.docx" \\
    --translations "translations.json" \\
    --output "output.docx" \\
    --author "Gemini" \\
    --strategy non_tag_only \\
    --verbose
        """
    )

    parser.add_argument('--input', required=True, help='è¾“å…¥ Word æ–‡æ¡£è·¯å¾„')
    parser.add_argument('--translations', required=True, help='ç¿»è¯‘æ˜ å°„ JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', required=True, help='è¾“å‡º Word æ–‡æ¡£è·¯å¾„')
    parser.add_argument('--author', default='Translator', help='è¿½è¸ªä¿®è®¢ä½œè€…åç§°')
    parser.add_argument('--strategy',
                       choices=['all', 'tag_only', 'non_tag_only'],
                       default='all',
                       help='è¯»å–ç­–ç•¥')
    parser.add_argument('--verbose', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬ç»“æ„åˆ†æï¼‰')

    args = parser.parse_args()

    try:
        success, fail = update_translations(
            args.input,
            args.translations,
            args.output,
            args.author,
            args.verbose,
            args.strategy
        )

        sys.exit(0 if fail == 0 else 1)

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
