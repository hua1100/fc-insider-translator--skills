#!/usr/bin/env python3
"""
æ–¹æ¡ˆ 3: æ·±åº¦ XML åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
1. å®Œæ•´åˆ†æ Word æ–‡æ¡£çš„ XML ç»“æ„
2. æ˜¾ç¤ºæ¯ä¸ª run çš„è¯¦ç»†å±æ€§ï¼ˆæ ·å¼ã€å­—ä½“ã€é¢œè‰²ç­‰ï¼‰
3. å¯¼å‡ºåŸå§‹ XML ä»¥ä¾›æ£€æŸ¥
4. æä¾›åŸºäºå®é™…ç»“æ„çš„è§£å†³æ–¹æ¡ˆå»ºè®®

ä½¿ç”¨æ–¹æ³•ï¼š
python3 analyze_word_structure_deep.py \
  --input "input.docx" \
  --sample-segment "11d76b912e-c3c9-456c-a895-7f4778e6a43f" \
  --export-xml
"""

import argparse
import sys
from pathlib import Path
from typing import Optional, List, Dict
import json

try:
    from docx import Document
    from docx.oxml.ns import qn
    from lxml import etree
except ImportError:
    print("é”™è¯¯ï¼šéœ€è¦å®‰è£… python-docx å’Œ lxml")
    print("è¿è¡Œ: pip install python-docx lxml")
    sys.exit(1)


def get_run_properties(run) -> Dict:
    """
    è·å– run çš„æ‰€æœ‰å±æ€§

    è¿”å›ï¼š
    - style: æ ·å¼åç§°
    - bold: æ˜¯å¦ç²—ä½“
    - italic: æ˜¯å¦æ–œä½“
    - underline: ä¸‹åˆ’çº¿ç±»å‹
    - color: æ–‡æœ¬é¢œè‰²
    - font_name: å­—ä½“åç§°
    - font_size: å­—ä½“å¤§å°
    - all_xml_properties: åŸå§‹ XML å±æ€§
    """
    properties = {
        'style': None,
        'bold': False,
        'italic': False,
        'underline': None,
        'color': None,
        'font_name': None,
        'font_size': None,
        'all_xml_properties': []
    }

    run_element = run._element
    rpr = run_element.find(qn('w:rPr'))

    if rpr is not None:
        # æ ·å¼
        r_style = rpr.find(qn('w:rStyle'))
        if r_style is not None:
            properties['style'] = r_style.get(qn('w:val'))

        # ç²—ä½“
        bold = rpr.find(qn('w:b'))
        if bold is not None:
            properties['bold'] = True

        # æ–œä½“
        italic = rpr.find(qn('w:i'))
        if italic is not None:
            properties['italic'] = True

        # ä¸‹åˆ’çº¿
        underline = rpr.find(qn('w:u'))
        if underline is not None:
            properties['underline'] = underline.get(qn('w:val'))

        # é¢œè‰²
        color = rpr.find(qn('w:color'))
        if color is not None:
            properties['color'] = color.get(qn('w:val'))

        # å­—ä½“
        r_fonts = rpr.find(qn('w:rFonts'))
        if r_fonts is not None:
            properties['font_name'] = r_fonts.get(qn('w:ascii'))

        # å­—ä½“å¤§å°
        sz = rpr.find(qn('w:sz'))
        if sz is not None:
            properties['font_size'] = sz.get(qn('w:val'))

        # æ”¶é›†æ‰€æœ‰ XML å±æ€§
        for child in rpr:
            tag_name = child.tag.split('}')[-1]  # å»æ‰å‘½åç©ºé—´
            attrs = dict(child.attrib)
            properties['all_xml_properties'].append({
                'tag': tag_name,
                'attributes': attrs
            })

    return properties


def analyze_cell_deep(cell, cell_name: str = "å•å…ƒæ ¼") -> Dict:
    """
    æ·±åº¦åˆ†æå•å…ƒæ ¼ç»“æ„

    è¿”å›å®Œæ•´çš„ç»“æ„ä¿¡æ¯
    """
    analysis = {
        'cell_name': cell_name,
        'total_paragraphs': len(cell.paragraphs),
        'total_runs': 0,
        'paragraphs': [],
        'summary': {
            'has_tag_style': False,
            'has_non_tag_style': False,
            'tag_style_count': 0,
            'non_tag_style_count': 0,
            'total_text_length': 0,
            'styles_found': set()
        }
    }

    for para_idx, paragraph in enumerate(cell.paragraphs):
        para_info = {
            'index': para_idx,
            'text': paragraph.text,
            'text_length': len(paragraph.text),
            'runs_count': len(paragraph.runs),
            'runs': []
        }

        for run_idx, run in enumerate(paragraph.runs):
            props = get_run_properties(run)

            run_info = {
                'index': run_idx,
                'text': run.text,
                'text_length': len(run.text) if run.text else 0,
                'properties': props
            }

            # ç»Ÿè®¡
            analysis['total_runs'] += 1
            if run.text:
                analysis['summary']['total_text_length'] += len(run.text)

            if props['style']:
                analysis['summary']['styles_found'].add(props['style'])

            if props['style'] == 'Tag':
                analysis['summary']['has_tag_style'] = True
                analysis['summary']['tag_style_count'] += 1
            else:
                analysis['summary']['has_non_tag_style'] = True
                analysis['summary']['non_tag_style_count'] += 1

            para_info['runs'].append(run_info)

        analysis['paragraphs'].append(para_info)

    # è½¬æ¢ set ä¸º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
    analysis['summary']['styles_found'] = list(analysis['summary']['styles_found'])

    return analysis


def export_cell_xml(cell, output_path: str):
    """
    å¯¼å‡ºå•å…ƒæ ¼çš„åŸå§‹ XML

    å¸®åŠ©ç”¨æˆ·æŸ¥çœ‹çœŸå®çš„ XML ç»“æ„
    """
    cell_element = cell._element
    xml_string = etree.tostring(
        cell_element,
        pretty_print=True,
        encoding='unicode'
    )

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(xml_string)

    print(f"âœ“ XML å·²å¯¼å‡ºåˆ°: {output_path}")


def print_analysis_report(analysis: Dict, verbose: bool = False):
    """
    æ‰“å°åˆ†ææŠ¥å‘Š
    """
    print(f"\n{'='*80}")
    print(f"å•å…ƒæ ¼åˆ†ææŠ¥å‘Š: {analysis['cell_name']}")
    print(f"{'='*80}")

    # æ‘˜è¦
    summary = analysis['summary']
    print(f"\nğŸ“Š æ‘˜è¦:")
    print(f"  æ€»æ®µè½æ•°: {analysis['total_paragraphs']}")
    print(f"  æ€» runs æ•°: {analysis['total_runs']}")
    print(f"  æ€»æ–‡æœ¬é•¿åº¦: {summary['total_text_length']} å­—ç¬¦")
    print(f"  Tag æ ·å¼ runs: {summary['tag_style_count']}")
    print(f"  é Tag æ ·å¼ runs: {summary['non_tag_style_count']}")
    print(f"  å‘ç°çš„æ ·å¼: {', '.join(summary['styles_found']) if summary['styles_found'] else 'æ— '}")

    # è¯¦ç»†æ®µè½ä¿¡æ¯
    print(f"\nğŸ“ æ®µè½è¯¦æƒ…:")
    for para in analysis['paragraphs']:
        print(f"\n  æ®µè½ {para['index']}:")
        print(f"    æ–‡æœ¬: '{para['text'][:100]}{'...' if len(para['text']) > 100 else ''}'")
        print(f"    é•¿åº¦: {para['text_length']} å­—ç¬¦")
        print(f"    Runs: {para['runs_count']}")

        if verbose:
            for run in para['runs']:
                print(f"\n      Run {run['index']}:")
                print(f"        æ–‡æœ¬: '{run['text'][:50] if run['text'] else '(ç©º)'}{'...' if run['text'] and len(run['text']) > 50 else ''}'")
                print(f"        é•¿åº¦: {run['text_length']} å­—ç¬¦")

                props = run['properties']
                print(f"        æ ·å¼: {props['style'] or '(æ— )'}")
                if props['bold']:
                    print(f"        ç²—ä½“: æ˜¯")
                if props['italic']:
                    print(f"        æ–œä½“: æ˜¯")
                if props['underline']:
                    print(f"        ä¸‹åˆ’çº¿: {props['underline']}")
                if props['color']:
                    print(f"        é¢œè‰²: {props['color']}")
                if props['font_name']:
                    print(f"        å­—ä½“: {props['font_name']}")
                if props['font_size']:
                    print(f"        å¤§å°: {props['font_size']}")

                if props['all_xml_properties']:
                    print(f"        XML å±æ€§:")
                    for xml_prop in props['all_xml_properties']:
                        print(f"          <{xml_prop['tag']}> {xml_prop['attributes']}")


def generate_solution_recommendation(analysis: Dict) -> str:
    """
    åŸºäºåˆ†æç»“æœç”Ÿæˆè§£å†³æ–¹æ¡ˆå»ºè®®
    """
    summary = analysis['summary']

    recommendations = []
    recommendations.append("\n" + "="*80)
    recommendations.append("ğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®")
    recommendations.append("="*80)

    # åˆ†ææ–‡æœ¬åˆ†å¸ƒ
    if summary['tag_style_count'] == 0:
        recommendations.append("\nâš ï¸  å‘ç°ï¼šæ²¡æœ‰ä»»ä½• Tag æ ·å¼çš„ runs")
        recommendations.append("   å»ºè®®ï¼šä½¿ç”¨ cell.text ç›´æ¥è¯»å–ï¼Œç„¶åç”¨æ­£åˆ™è¿‡æ»¤å ä½ç¬¦")
        recommendations.append("   è„šæœ¬ï¼šupdate_fc_insider_smart.py --strategy all")

    elif summary['non_tag_style_count'] == 0:
        recommendations.append("\nâœ“ å‘ç°ï¼šæ‰€æœ‰ runs éƒ½æ˜¯ Tag æ ·å¼")
        recommendations.append("  å»ºè®®ï¼šè¯»å–æ‰€æœ‰ Tag æ ·å¼æ–‡æœ¬ï¼Œç„¶åç”¨æ­£åˆ™è¿‡æ»¤å ä½ç¬¦")
        recommendations.append("  è„šæœ¬ï¼šupdate_fc_insider_reverse.py --method only_tags")
        recommendations.append("  æˆ–è€…ï¼šupdate_fc_insider_smart.py --strategy tag_only")

    else:
        recommendations.append(f"\nâœ“ å‘ç°ï¼šæ··åˆæ ·å¼")
        recommendations.append(f"  - Tag æ ·å¼ runs: {summary['tag_style_count']}")
        recommendations.append(f"  - é Tag æ ·å¼ runs: {summary['non_tag_style_count']}")

        # æ£€æŸ¥å“ªç§æ ·å¼åŒ…å«æ›´å¤šæ–‡æœ¬
        tag_text_length = 0
        non_tag_text_length = 0

        for para in analysis['paragraphs']:
            for run in para['runs']:
                if run['properties']['style'] == 'Tag':
                    tag_text_length += run['text_length']
                else:
                    non_tag_text_length += run['text_length']

        recommendations.append(f"  - Tag æ ·å¼æ–‡æœ¬é•¿åº¦: {tag_text_length}")
        recommendations.append(f"  - é Tag æ ·å¼æ–‡æœ¬é•¿åº¦: {non_tag_text_length}")

        if tag_text_length > non_tag_text_length:
            recommendations.append("\n  ğŸ’¡ å»ºè®®ï¼šä¸»è¦å†…å®¹åœ¨ Tag æ ·å¼ä¸­")
            recommendations.append("     è„šæœ¬ï¼šupdate_fc_insider_smart.py --strategy tag_only --verbose")
        else:
            recommendations.append("\n  ğŸ’¡ å»ºè®®ï¼šä¸»è¦å†…å®¹åœ¨é Tag æ ·å¼ä¸­")
            recommendations.append("     è„šæœ¬ï¼šupdate_fc_insider_smart.py --strategy non_tag_only --verbose")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦æŸ¥çœ‹ XML
    if summary['total_runs'] > 10:
        recommendations.append("\nâš ï¸  å¤æ‚ç»“æ„ï¼šruns æ•°é‡è¾ƒå¤š")
        recommendations.append("   å»ºè®®ï¼šä½¿ç”¨ --export-xml å¯¼å‡º XML è¿›è¡Œè¯¦ç»†æ£€æŸ¥")

    recommendations.append("\n" + "="*80)

    return '\n'.join(recommendations)


def find_table(doc) -> Optional:
    """æŸ¥æ‰¾æ–‡æ¡£ä¸­çš„ç¬¬ä¸€ä¸ªè¡¨æ ¼"""
    if not doc.tables:
        return None
    return doc.tables[0]


def main():
    parser = argparse.ArgumentParser(
        description='æ–¹æ¡ˆ 3: æ·±åº¦ XML åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # åŸºæœ¬åˆ†æ
  python3 analyze_word_structure_deep.py \\
    --input "input.docx" \\
    --sample-segment "11d76b912e-c3c9-456c-a895-7f4778e6a43f"

  # è¯¦ç»†åˆ†æï¼ˆæ˜¾ç¤ºæ‰€æœ‰ run å±æ€§ï¼‰
  python3 analyze_word_structure_deep.py \\
    --input "input.docx" \\
    --sample-segment "11d76b912e-c3c9-456c-a895-7f4778e6a43f" \\
    --verbose

  # å¯¼å‡º XML
  python3 analyze_word_structure_deep.py \\
    --input "input.docx" \\
    --sample-segment "11d76b912e-c3c9-456c-a895-7f4778e6a43f" \\
    --export-xml

  # å¯¼å‡º JSON
  python3 analyze_word_structure_deep.py \\
    --input "input.docx" \\
    --sample-segment "11d76b912e-c3c9-456c-a895-7f4778e6a43f" \\
    --export-json analysis.json
        """
    )

    parser.add_argument('--input', required=True, help='è¾“å…¥ Word æ–‡æ¡£è·¯å¾„')
    parser.add_argument('--sample-segment', help='æ ·æœ¬ Segment IDï¼ˆåˆ†ææ­¤è¡Œï¼‰')
    parser.add_argument('--verbose', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†çš„ run å±æ€§')
    parser.add_argument('--export-xml', action='store_true', help='å¯¼å‡ºå•å…ƒæ ¼çš„åŸå§‹ XML')
    parser.add_argument('--export-json', help='å¯¼å‡ºåˆ†æç»“æœä¸º JSON æ–‡ä»¶')

    args = parser.parse_args()

    try:
        # åŠ è½½æ–‡æ¡£
        print(f"\nğŸ“– åŠ è½½æ–‡æ¡£: {args.input}")
        doc = Document(args.input)

        # æŸ¥æ‰¾è¡¨æ ¼
        table = find_table(doc)
        if not table:
            print("âŒ é”™è¯¯ï¼šæ–‡æ¡£ä¸­æœªæ‰¾åˆ°è¡¨æ ¼")
            sys.exit(1)

        print(f"âœ“ æ‰¾åˆ°è¡¨æ ¼ï¼Œå…± {len(table.rows)} è¡Œ")

        # å¦‚æœæŒ‡å®šäº† sample_segmentï¼Œåˆ†æè¯¥è¡Œ
        if args.sample_segment:
            # æŸ¥æ‰¾è¡Œ
            target_row = None
            target_row_idx = None

            for i, row in enumerate(table.rows[1:], start=1):  # è·³è¿‡è¡¨å¤´
                if len(row.cells) >= 4:
                    segment_id = row.cells[0].text.strip()
                    if segment_id == args.sample_segment:
                        target_row = row
                        target_row_idx = i
                        break

            if not target_row:
                print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° Segment ID: {args.sample_segment}")
                sys.exit(1)

            print(f"âœ“ æ‰¾åˆ°ç›®æ ‡è¡Œ: ç¬¬ {target_row_idx} è¡Œ")

            # åˆ†æ Target åˆ—ï¼ˆç¬¬ 4 åˆ—ï¼Œç´¢å¼• 3ï¼‰
            target_cell = target_row.cells[3]
            analysis = analyze_cell_deep(target_cell, f"Target åˆ— (è¡Œ {target_row_idx})")

            # æ‰“å°æŠ¥å‘Š
            print_analysis_report(analysis, args.verbose)

            # ç”Ÿæˆå»ºè®®
            recommendation = generate_solution_recommendation(analysis)
            print(recommendation)

            # å¯¼å‡º XML
            if args.export_xml:
                xml_filename = f"cell_row{target_row_idx}_xml.xml"
                export_cell_xml(target_cell, xml_filename)

            # å¯¼å‡º JSON
            if args.export_json:
                with open(args.export_json, 'w', encoding='utf-8') as f:
                    json.dump(analysis, f, ensure_ascii=False, indent=2)
                print(f"âœ“ JSON å·²å¯¼å‡ºåˆ°: {args.export_json}")

        else:
            # æ²¡æœ‰æŒ‡å®š segmentï¼Œåˆ†ææ‰€æœ‰è¡Œçš„ Target åˆ—
            print("\nåˆ†ææ‰€æœ‰è¡Œçš„ Target åˆ—...")

            all_analyses = []

            for i, row in enumerate(table.rows[1:], start=1):
                if len(row.cells) >= 4:
                    segment_id = row.cells[0].text.strip()
                    target_cell = row.cells[3]

                    analysis = analyze_cell_deep(target_cell, f"è¡Œ {i} ({segment_id})")
                    all_analyses.append(analysis)

            # æ‰“å°æ‘˜è¦
            print(f"\n{'='*80}")
            print(f"æ‰€æœ‰è¡Œæ‘˜è¦ ({len(all_analyses)} è¡Œ)")
            print(f"{'='*80}")

            for analysis in all_analyses:
                summary = analysis['summary']
                print(f"\n{analysis['cell_name']}:")
                print(f"  Runs: {analysis['total_runs']}, Tagæ ·å¼: {summary['tag_style_count']}, éTag: {summary['non_tag_style_count']}")
                print(f"  æ–‡æœ¬é•¿åº¦: {summary['total_text_length']}")

            # å¯¼å‡º JSON
            if args.export_json:
                with open(args.export_json, 'w', encoding='utf-8') as f:
                    json.dump(all_analyses, f, ensure_ascii=False, indent=2)
                print(f"\nâœ“ JSON å·²å¯¼å‡ºåˆ°: {args.export_json}")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
